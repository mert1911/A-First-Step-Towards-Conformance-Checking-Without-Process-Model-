{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00c6b8de",
   "metadata": {},
   "source": [
    "# Installations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31dcdf15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Installations\n",
    "\n",
    "# install once necessary libraries\n",
    "\n",
    "!pip install pandas\n",
    "!pip install -U scikit-learn\n",
    "!pip install pm4py\n",
    "!pip install kneed\n",
    "!pip install torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47f1af5c",
   "metadata": {},
   "source": [
    "# Import Event Log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cab9ba88",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/mert2/.conda/envs/thesis/lib/python3.11/site-packages/pm4py/objects/log/util/dataframe_utils.py:177: UserWarning: Could not infer format, so each element will be parsed individually, falling back to `dateutil`. To ensure parsing is consistent and as-expected, please specify a format.\n",
      "  df[col] = pd.to_datetime(df[col], utc=True)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>org:resource</th>\n",
       "      <th>lifecycle:transition</th>\n",
       "      <th>concept:name</th>\n",
       "      <th>time:timestamp</th>\n",
       "      <th>case:REG_DATE</th>\n",
       "      <th>case:concept:name</th>\n",
       "      <th>case:AMOUNT_REQ</th>\n",
       "      <th>@@index</th>\n",
       "      <th>@@case_index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>112</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>A_SUBMITTED</td>\n",
       "      <td>2011-10-01 00:38:44.546000+02:00</td>\n",
       "      <td>2011-10-01 00:38:44.546000+02:00</td>\n",
       "      <td>173688</td>\n",
       "      <td>20000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>112</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>A_PARTLYSUBMITTED</td>\n",
       "      <td>2011-10-01 00:38:44.880000+02:00</td>\n",
       "      <td>2011-10-01 00:38:44.546000+02:00</td>\n",
       "      <td>173688</td>\n",
       "      <td>20000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>112</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>A_PREACCEPTED</td>\n",
       "      <td>2011-10-01 00:39:37.906000+02:00</td>\n",
       "      <td>2011-10-01 00:38:44.546000+02:00</td>\n",
       "      <td>173688</td>\n",
       "      <td>20000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10862</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>A_ACCEPTED</td>\n",
       "      <td>2011-10-01 11:42:43.308000+02:00</td>\n",
       "      <td>2011-10-01 00:38:44.546000+02:00</td>\n",
       "      <td>173688</td>\n",
       "      <td>20000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10862</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>A_FINALIZED</td>\n",
       "      <td>2011-10-01 11:45:09.243000+02:00</td>\n",
       "      <td>2011-10-01 00:38:44.546000+02:00</td>\n",
       "      <td>173688</td>\n",
       "      <td>20000</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60844</th>\n",
       "      <td>10933</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>A_ACCEPTED</td>\n",
       "      <td>2012-03-01 20:17:22.457000+01:00</td>\n",
       "      <td>2012-02-29 23:43:09.766000+01:00</td>\n",
       "      <td>214373</td>\n",
       "      <td>8500</td>\n",
       "      <td>60844</td>\n",
       "      <td>13085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60845</th>\n",
       "      <td>10933</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>A_FINALIZED</td>\n",
       "      <td>2012-03-01 20:22:38.593000+01:00</td>\n",
       "      <td>2012-02-29 23:43:09.766000+01:00</td>\n",
       "      <td>214373</td>\n",
       "      <td>8500</td>\n",
       "      <td>60845</td>\n",
       "      <td>13085</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60846</th>\n",
       "      <td>112</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>A_SUBMITTED</td>\n",
       "      <td>2012-02-29 23:51:16.799000+01:00</td>\n",
       "      <td>2012-02-29 23:51:16.799000+01:00</td>\n",
       "      <td>214376</td>\n",
       "      <td>15000</td>\n",
       "      <td>60846</td>\n",
       "      <td>13086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60847</th>\n",
       "      <td>112</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>A_PARTLYSUBMITTED</td>\n",
       "      <td>2012-02-29 23:51:17.423000+01:00</td>\n",
       "      <td>2012-02-29 23:51:16.799000+01:00</td>\n",
       "      <td>214376</td>\n",
       "      <td>15000</td>\n",
       "      <td>60847</td>\n",
       "      <td>13086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60848</th>\n",
       "      <td>11169</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>A_DECLINED</td>\n",
       "      <td>2012-03-01 09:27:37.118000+01:00</td>\n",
       "      <td>2012-02-29 23:51:16.799000+01:00</td>\n",
       "      <td>214376</td>\n",
       "      <td>15000</td>\n",
       "      <td>60848</td>\n",
       "      <td>13086</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60849 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       org:resource lifecycle:transition       concept:name  \\\n",
       "0               112             COMPLETE        A_SUBMITTED   \n",
       "1               112             COMPLETE  A_PARTLYSUBMITTED   \n",
       "2               112             COMPLETE      A_PREACCEPTED   \n",
       "3             10862             COMPLETE         A_ACCEPTED   \n",
       "4             10862             COMPLETE        A_FINALIZED   \n",
       "...             ...                  ...                ...   \n",
       "60844         10933             COMPLETE         A_ACCEPTED   \n",
       "60845         10933             COMPLETE        A_FINALIZED   \n",
       "60846           112             COMPLETE        A_SUBMITTED   \n",
       "60847           112             COMPLETE  A_PARTLYSUBMITTED   \n",
       "60848         11169             COMPLETE         A_DECLINED   \n",
       "\n",
       "                         time:timestamp                     case:REG_DATE  \\\n",
       "0      2011-10-01 00:38:44.546000+02:00  2011-10-01 00:38:44.546000+02:00   \n",
       "1      2011-10-01 00:38:44.880000+02:00  2011-10-01 00:38:44.546000+02:00   \n",
       "2      2011-10-01 00:39:37.906000+02:00  2011-10-01 00:38:44.546000+02:00   \n",
       "3      2011-10-01 11:42:43.308000+02:00  2011-10-01 00:38:44.546000+02:00   \n",
       "4      2011-10-01 11:45:09.243000+02:00  2011-10-01 00:38:44.546000+02:00   \n",
       "...                                 ...                               ...   \n",
       "60844  2012-03-01 20:17:22.457000+01:00  2012-02-29 23:43:09.766000+01:00   \n",
       "60845  2012-03-01 20:22:38.593000+01:00  2012-02-29 23:43:09.766000+01:00   \n",
       "60846  2012-02-29 23:51:16.799000+01:00  2012-02-29 23:51:16.799000+01:00   \n",
       "60847  2012-02-29 23:51:17.423000+01:00  2012-02-29 23:51:16.799000+01:00   \n",
       "60848  2012-03-01 09:27:37.118000+01:00  2012-02-29 23:51:16.799000+01:00   \n",
       "\n",
       "      case:concept:name  case:AMOUNT_REQ  @@index  @@case_index  \n",
       "0                173688            20000        0             0  \n",
       "1                173688            20000        1             0  \n",
       "2                173688            20000        2             0  \n",
       "3                173688            20000        3             0  \n",
       "4                173688            20000        4             0  \n",
       "...                 ...              ...      ...           ...  \n",
       "60844            214373             8500    60844         13085  \n",
       "60845            214373             8500    60845         13085  \n",
       "60846            214376            15000    60846         13086  \n",
       "60847            214376            15000    60847         13086  \n",
       "60848            214376            15000    60848         13086  \n",
       "\n",
       "[60849 rows x 9 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pm4py\n",
    "from pm4py.objects.conversion.log import converter as log_converter\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Read the CSV file\n",
    "    dataframe = pd.read_csv('model_A.csv', sep=',')  \n",
    "\n",
    "    # Drop the first column without knowing its name\n",
    "    dataframe = dataframe.drop(dataframe.columns[0], axis=1)\n",
    "\n",
    "    # Format the dataframe\n",
    "    dataframe = pm4py.format_dataframe(\n",
    "        dataframe, \n",
    "        case_id='case:concept:name', \n",
    "        activity_key='concept:name', \n",
    "        timestamp_key='time:timestamp'\n",
    "    )\n",
    "\n",
    "    # Convert the dataframe to event log\n",
    "    log = log_converter.apply(dataframe)\n",
    "    \n",
    "dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba199329",
   "metadata": {},
   "source": [
    "# Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953e8a99",
   "metadata": {},
   "source": [
    "## Integer Encoding "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9269f1c7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>org:resource</th>\n",
       "      <th>lifecycle:transition</th>\n",
       "      <th>concept:name</th>\n",
       "      <th>time:timestamp</th>\n",
       "      <th>case:REG_DATE</th>\n",
       "      <th>case:concept:name</th>\n",
       "      <th>case:AMOUNT_REQ</th>\n",
       "      <th>@@index</th>\n",
       "      <th>@@case_index</th>\n",
       "      <th>activity_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>112</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>A_SUBMITTED</td>\n",
       "      <td>2011-10-01 00:38:44.546000+02:00</td>\n",
       "      <td>2011-10-01 00:38:44.546000+02:00</td>\n",
       "      <td>173688</td>\n",
       "      <td>20000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>112</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>A_PARTLYSUBMITTED</td>\n",
       "      <td>2011-10-01 00:38:44.880000+02:00</td>\n",
       "      <td>2011-10-01 00:38:44.546000+02:00</td>\n",
       "      <td>173688</td>\n",
       "      <td>20000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>112</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>A_PREACCEPTED</td>\n",
       "      <td>2011-10-01 00:39:37.906000+02:00</td>\n",
       "      <td>2011-10-01 00:38:44.546000+02:00</td>\n",
       "      <td>173688</td>\n",
       "      <td>20000</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>10862</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>A_ACCEPTED</td>\n",
       "      <td>2011-10-01 11:42:43.308000+02:00</td>\n",
       "      <td>2011-10-01 00:38:44.546000+02:00</td>\n",
       "      <td>173688</td>\n",
       "      <td>20000</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10862</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>A_FINALIZED</td>\n",
       "      <td>2011-10-01 11:45:09.243000+02:00</td>\n",
       "      <td>2011-10-01 00:38:44.546000+02:00</td>\n",
       "      <td>173688</td>\n",
       "      <td>20000</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60844</th>\n",
       "      <td>10933</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>A_ACCEPTED</td>\n",
       "      <td>2012-03-01 20:17:22.457000+01:00</td>\n",
       "      <td>2012-02-29 23:43:09.766000+01:00</td>\n",
       "      <td>214373</td>\n",
       "      <td>8500</td>\n",
       "      <td>60844</td>\n",
       "      <td>13085</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60845</th>\n",
       "      <td>10933</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>A_FINALIZED</td>\n",
       "      <td>2012-03-01 20:22:38.593000+01:00</td>\n",
       "      <td>2012-02-29 23:43:09.766000+01:00</td>\n",
       "      <td>214373</td>\n",
       "      <td>8500</td>\n",
       "      <td>60845</td>\n",
       "      <td>13085</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60846</th>\n",
       "      <td>112</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>A_SUBMITTED</td>\n",
       "      <td>2012-02-29 23:51:16.799000+01:00</td>\n",
       "      <td>2012-02-29 23:51:16.799000+01:00</td>\n",
       "      <td>214376</td>\n",
       "      <td>15000</td>\n",
       "      <td>60846</td>\n",
       "      <td>13086</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60847</th>\n",
       "      <td>112</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>A_PARTLYSUBMITTED</td>\n",
       "      <td>2012-02-29 23:51:17.423000+01:00</td>\n",
       "      <td>2012-02-29 23:51:16.799000+01:00</td>\n",
       "      <td>214376</td>\n",
       "      <td>15000</td>\n",
       "      <td>60847</td>\n",
       "      <td>13086</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60848</th>\n",
       "      <td>11169</td>\n",
       "      <td>COMPLETE</td>\n",
       "      <td>A_DECLINED</td>\n",
       "      <td>2012-03-01 09:27:37.118000+01:00</td>\n",
       "      <td>2012-02-29 23:51:16.799000+01:00</td>\n",
       "      <td>214376</td>\n",
       "      <td>15000</td>\n",
       "      <td>60848</td>\n",
       "      <td>13086</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>60849 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       org:resource lifecycle:transition       concept:name  \\\n",
       "0               112             COMPLETE        A_SUBMITTED   \n",
       "1               112             COMPLETE  A_PARTLYSUBMITTED   \n",
       "2               112             COMPLETE      A_PREACCEPTED   \n",
       "3             10862             COMPLETE         A_ACCEPTED   \n",
       "4             10862             COMPLETE        A_FINALIZED   \n",
       "...             ...                  ...                ...   \n",
       "60844         10933             COMPLETE         A_ACCEPTED   \n",
       "60845         10933             COMPLETE        A_FINALIZED   \n",
       "60846           112             COMPLETE        A_SUBMITTED   \n",
       "60847           112             COMPLETE  A_PARTLYSUBMITTED   \n",
       "60848         11169             COMPLETE         A_DECLINED   \n",
       "\n",
       "                         time:timestamp                     case:REG_DATE  \\\n",
       "0      2011-10-01 00:38:44.546000+02:00  2011-10-01 00:38:44.546000+02:00   \n",
       "1      2011-10-01 00:38:44.880000+02:00  2011-10-01 00:38:44.546000+02:00   \n",
       "2      2011-10-01 00:39:37.906000+02:00  2011-10-01 00:38:44.546000+02:00   \n",
       "3      2011-10-01 11:42:43.308000+02:00  2011-10-01 00:38:44.546000+02:00   \n",
       "4      2011-10-01 11:45:09.243000+02:00  2011-10-01 00:38:44.546000+02:00   \n",
       "...                                 ...                               ...   \n",
       "60844  2012-03-01 20:17:22.457000+01:00  2012-02-29 23:43:09.766000+01:00   \n",
       "60845  2012-03-01 20:22:38.593000+01:00  2012-02-29 23:43:09.766000+01:00   \n",
       "60846  2012-02-29 23:51:16.799000+01:00  2012-02-29 23:51:16.799000+01:00   \n",
       "60847  2012-02-29 23:51:17.423000+01:00  2012-02-29 23:51:16.799000+01:00   \n",
       "60848  2012-03-01 09:27:37.118000+01:00  2012-02-29 23:51:16.799000+01:00   \n",
       "\n",
       "      case:concept:name  case:AMOUNT_REQ  @@index  @@case_index  \\\n",
       "0                173688            20000        0             0   \n",
       "1                173688            20000        1             0   \n",
       "2                173688            20000        2             0   \n",
       "3                173688            20000        3             0   \n",
       "4                173688            20000        4             0   \n",
       "...                 ...              ...      ...           ...   \n",
       "60844            214373             8500    60844         13085   \n",
       "60845            214373             8500    60845         13085   \n",
       "60846            214376            15000    60846         13086   \n",
       "60847            214376            15000    60847         13086   \n",
       "60848            214376            15000    60848         13086   \n",
       "\n",
       "       activity_encoded  \n",
       "0                     9  \n",
       "1                     6  \n",
       "2                     7  \n",
       "3                     0  \n",
       "4                     5  \n",
       "...                 ...  \n",
       "60844                 0  \n",
       "60845                 5  \n",
       "60846                 9  \n",
       "60847                 6  \n",
       "60848                 4  \n",
       "\n",
       "[60849 rows x 10 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Create an instance of LabelEncoder\n",
    "label_encoder = LabelEncoder()\n",
    "\n",
    "# Fit label encoder and return encoded labels\n",
    "dataframe['activity_encoded'] = label_encoder.fit_transform(dataframe['concept:name'])\n",
    "\n",
    "# Now the 'dataframe' has a new column 'activity_encoded' with integer encoded values of the 'activity' column\n",
    "dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d10b45d",
   "metadata": {},
   "source": [
    "## Extract Traces "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b853cb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "@@case_index\n",
       "0        [9, 6, 7, 0, 5, 8, 2, 1]\n",
       "1        [9, 6, 7, 0, 5, 2, 8, 1]\n",
       "2        [9, 6, 7, 0, 5, 2, 8, 1]\n",
       "3                       [9, 6, 4]\n",
       "4                       [9, 6, 4]\n",
       "                   ...           \n",
       "13082             [9, 6, 7, 0, 5]\n",
       "13083                   [9, 6, 4]\n",
       "13084                   [9, 6, 4]\n",
       "13085             [9, 6, 7, 0, 5]\n",
       "13086                   [9, 6, 4]\n",
       "Name: activity_encoded, Length: 13087, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Group by case index to get individual traces\n",
    "traces = dataframe.groupby('@@case_index')['activity_encoded'].apply(list)\n",
    "traces"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0baab624",
   "metadata": {},
   "source": [
    "## Padding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "595b98fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[9, 6, 7,  ..., 8, 2, 1],\n",
       "        [9, 6, 7,  ..., 2, 8, 1],\n",
       "        [9, 6, 7,  ..., 2, 8, 1],\n",
       "        ...,\n",
       "        [9, 6, 4,  ..., 0, 0, 0],\n",
       "        [9, 6, 7,  ..., 0, 0, 0],\n",
       "        [9, 6, 4,  ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Post-Padding\n",
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence\n",
    "\n",
    "# First, we convert the pandas Series 'traces' to a list of PyTorch tensors\n",
    "traces_tensors = [torch.tensor(trace) for trace in traces]\n",
    "\n",
    "# Then, we apply padding to this list of tensors\n",
    "# We are assuming here that your traces are sequences of integers that represent encoded activities\n",
    "# pad_sequence requires the input to be a list (or other iterable) of tensors\n",
    "padded_traces = pad_sequence(traces_tensors, batch_first=True)\n",
    "\n",
    "# Now 'padded_traces' is a tensor with each row representing a trace and zeros padding the sequences to equal length\n",
    "padded_traces"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "548730de",
   "metadata": {},
   "source": [
    "# Build Input X and output Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69e628d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming 'padded_traces' is already created as per the previous discussion.\n",
    "\n",
    "# Determine the integer for 'END' token, assuming it's the max(encoded_activities) + 1\n",
    "end_token = padded_traces.max() + 1\n",
    "\n",
    "# Initialize lists to hold the input sequences X and the targets Y\n",
    "X = []\n",
    "Y = []\n",
    "\n",
    "# Iterate through each trace\n",
    "for trace in padded_traces:\n",
    "    # Initialize the sequence with the 'null' token\n",
    "    seq = [0]  \n",
    "    for activity in trace:\n",
    "        # Exclude padding (0) and end token (if already included)\n",
    "        if activity.item() not in (0, end_token):\n",
    "            # Append the current sequence to X\n",
    "            X.append(seq.copy())\n",
    "            # Append the next activity as the target to Y\n",
    "            Y.append(activity.item())\n",
    "            # Add the current activity to the sequence\n",
    "            seq.append(activity.item())\n",
    "    # After the last activity in the trace, append the 'END' token to the sequence and to Y\n",
    "    X.append(seq.copy())\n",
    "    Y.append(end_token)\n",
    "\n",
    "# Convert X and Y to PyTorch tensors\n",
    "X_tensor = pad_sequence([torch.tensor(x) for x in X], batch_first=True, padding_value=0)\n",
    "Y_tensor = torch.tensor(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "779aafc8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([68823, 8])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a6c88e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_tensor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76bc19ba",
   "metadata": {},
   "source": [
    "# Optional: Prepare Test and Train Data"
   ]
  },
  {
   "cell_type": "raw",
   "id": "dadfd599",
   "metadata": {},
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Convert tensors to numpy arrays for train_test_split function\n",
    "X_numpy = X_tensor.numpy()\n",
    "Y_numpy = Y_tensor.numpy()\n",
    "\n",
    "# Split the data\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_numpy, Y_numpy, test_size=0.3, random_state=42)\n",
    "\n",
    "# Convert them back to tensors\n",
    "X_train_tensor = torch.tensor(X_train, dtype=torch.long).to(device)\n",
    "X_test_tensor = torch.tensor(X_test, dtype=torch.long).to(device)\n",
    "Y_train_tensor = torch.tensor(Y_train, dtype=torch.long).to(device)\n",
    "Y_test_tensor = torch.tensor(Y_test, dtype=torch.long).to(device)"
   ]
  },
  {
   "cell_type": "raw",
   "id": "8679c72f",
   "metadata": {},
   "source": [
    "X_tensor = X_train_tensor\n",
    "Y_tensor = Y_train_tensor"
   ]
  },
  {
   "cell_type": "raw",
   "id": "4226abcc",
   "metadata": {},
   "source": [
    "X_tensor.shape"
   ]
  },
  {
   "cell_type": "raw",
   "id": "d8034333",
   "metadata": {},
   "source": [
    "Y_tensor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13a83570",
   "metadata": {},
   "source": [
    "# LSTM Model Architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a628b9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class LSTMModel(nn.Module):\n",
    "    def __init__(self, num_activities, embedding_dim, hidden_dim, output_dim, dropout_prob=0.2):\n",
    "        super(LSTMModel, self).__init__()\n",
    "        self.embedding = nn.Embedding(num_activities, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first=True, dropout=dropout_prob)\n",
    "        self.fc = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        embedded = self.embedding(x)\n",
    "        lstm_out, (h_n, c_n) = self.lstm(embedded)\n",
    "        out = self.fc(lstm_out[:, -1, :])  # Output of the last LSTM cell\n",
    "        return out, h_n\n",
    "\n",
    "# Model parameters\n",
    "num_activities = end_token + 1 # define this based on your data\n",
    "embedding_dim = len(dataframe['concept:name'].unique())\n",
    "hidden_dim = 100\n",
    "output_dim = num_activities\n",
    "\n",
    "# Initialize model\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "lstm_model = LSTMModel(num_activities, embedding_dim, hidden_dim, output_dim, dropout_prob=0.2).to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66982278",
   "metadata": {},
   "source": [
    "# LSTM Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0be1c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(lstm_model.parameters())\n",
    "\n",
    "# Data preparation\n",
    "train_data = TensorDataset(X_tensor, Y_tensor)\n",
    "train_loader = DataLoader(train_data, batch_size=32, shuffle=True)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 50\n",
    "for epoch in range(num_epochs):\n",
    "    for inputs, targets in train_loader:\n",
    "        inputs, targets = inputs.to(device), targets.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs, _ = lstm_model(inputs)  # Ignore hidden states during training\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {loss.item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c19208dd",
   "metadata": {},
   "source": [
    "# Optional: Evaluation of LSTM Predictive Performance"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c76a4e7e",
   "metadata": {},
   "source": [
    "# Test data loader\n",
    "test_data = TensorDataset(X_test_tensor, Y_test_tensor)\n",
    "test_loader = DataLoader(test_data, batch_size=32)  # Adjust the batch size if necessary"
   ]
  },
  {
   "cell_type": "raw",
   "id": "fe0b2dd2",
   "metadata": {},
   "source": [
    "# Put the model in evaluation mode\n",
    "lstm_model.eval()\n",
    "\n",
    "# Initialize variables to track predictions and actuals\n",
    "total_predictions = 0\n",
    "correct_predictions = 0\n",
    "\n",
    "# Disable gradient computation during evaluation\n",
    "with torch.no_grad():\n",
    "    for inputs, targets in test_loader:\n",
    "        inputs = inputs.to(device)\n",
    "\n",
    "        # Get model predictions\n",
    "        outputs, _ = lstm_model(inputs)\n",
    "\n",
    "        # Convert outputs to predicted class labels\n",
    "        _, predicted_labels = torch.max(outputs.data, 1)\n",
    "\n",
    "        # Update total and correct predictions\n",
    "        total_predictions += targets.size(0)\n",
    "        correct_predictions += (predicted_labels == targets).sum().item()\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = correct_predictions / total_predictions\n",
    "print(f'Accuracy for predicting next activity: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7df3b50f",
   "metadata": {},
   "source": [
    "# Extract Trace Representations Using LSTM Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347198e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To collect hidden states for the entire dataset\n",
    "lstm_model.eval()  # Set the model to evaluation mode\n",
    "hidden_states = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for inputs in DataLoader(X_tensor, batch_size=1):  # Process one sequence at a time\n",
    "        inputs = inputs.to(device)\n",
    "        _, h_n = lstm_model(inputs)  # Get the hidden state\n",
    "        hidden_states.append(h_n.squeeze(0).cpu().numpy())  # Remove batch dimension and convert to numpy\n",
    "\n",
    "hidden_states = np.array(hidden_states)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85289e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_states = hidden_states.squeeze(1)  # Removes the singleton dimension\n",
    "\n",
    "# Check the new shape\n",
    "print(hidden_states.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f445c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Group by case index to get individual traces\n",
    "traces = dataframe.groupby('@@case_index')['concept:name'].apply(list)\n",
    "traces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e58c33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_state_pos = traces.apply(len).values\n",
    "hidden_state_pos = hidden_state_pos - 1\n",
    "hidden_state_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8934670f",
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_representations = [hidden_states[i-1] for i in hidden_state_pos]\n",
    "trace_representations = np.array(trace_representations)\n",
    "len(trace_representations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a35e592",
   "metadata": {},
   "outputs": [],
   "source": [
    "trace_representations.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee94afa1",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2695b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import matplotlib.pyplot as plt\n",
    "from kneed import KneeLocator\n",
    "\n",
    "# Elbow method to determine the optimal number of clusters\n",
    "distortions = []\n",
    "K = range(1, 10)\n",
    "for k in K:\n",
    "    kmeanModel = KMeans(n_clusters=k)\n",
    "    kmeanModel.fit(trace_representations)\n",
    "    distortions.append(kmeanModel.inertia_)\n",
    "\n",
    "# Plot the elbow graph\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.plot(K, distortions, 'bx-')\n",
    "plt.xlabel('Number of Clusters')\n",
    "plt.ylabel('SSE')\n",
    "plt.title('The Elbow Method showing the optimal k')\n",
    "plt.show()\n",
    "\n",
    "# Find the elbow point\n",
    "kl = KneeLocator(range(1, 10), distortions, curve=\"convex\", direction=\"decreasing\")\n",
    "print(\"Optimal number of clusters:\", kl.elbow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c393dcfa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Number of clusters\n",
    "k = kl.elbow\n",
    "\n",
    "# Create a KMeans instance with k clusters\n",
    "kmeans = KMeans(n_clusters=k, random_state=42)\n",
    "\n",
    "# Fit the model to the data\n",
    "kmeans.fit(trace_representations)\n",
    "\n",
    "# Predict the clusters for each trace\n",
    "clusters = kmeans.predict(trace_representations)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a08879f",
   "metadata": {},
   "source": [
    "# Cluster Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e048da8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the value of the silhouette coefficient ranges between -1 and 1\n",
    "# value close to 1 is considered as good\n",
    "\n",
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "# Calculate silhouette score\n",
    "silhouette_avg = silhouette_score(trace_representations, clusters)\n",
    "\n",
    "print(f\"Silhouette Coefficient: {silhouette_avg:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "419acf27",
   "metadata": {},
   "source": [
    "# Token-Based Replay for Conformance Checking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccdb7e2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pm4py\n",
    "from pm4py.objects.log.importer.xes import importer as xes_importer\n",
    "from pm4py.objects.bpmn.importer import importer as bpmn_importer\n",
    "from pm4py.algo.conformance.alignments.petri_net import algorithm as alignments_petri\n",
    "\n",
    "# 2. Import the given BPMN model\n",
    "bpmn_graph = bpmn_importer.apply(\"Model_A_corrected.bpmn\")\n",
    "\n",
    "# 3. Convert the BPMN to a Petri net\n",
    "net, im, fm = pm4py.convert_to_petri_net(bpmn_graph)\n",
    "\n",
    "# 4. Perform alignment-based conformance checking\n",
    "alignments = alignments_petri.apply(log, net, im, fm)\n",
    "\n",
    "# Calculate and print diagnostics\n",
    "fit_traces = sum(1 for trace in alignments if trace['fitness'] == 1.0)\n",
    "\n",
    "print(f\"Total traces: {len(log)}\")\n",
    "print(f\"Conform traces: {fit_traces}\")\n",
    "print(f\"Non-Conform traces: {len(log) - fit_traces}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2171bf1e",
   "metadata": {},
   "source": [
    "# Happy Cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd1bc941",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = kmeans.labels_\n",
    "\n",
    "# Identify the dominant cluster\n",
    "from collections import Counter\n",
    "counter = Counter(labels)\n",
    "happy_cluster = counter.most_common(1)[0][0]\n",
    "print(f\"Happy Cluster: {happy_cluster}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3042a649",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the indices of the data points belonging to the happy cluster\n",
    "happy_cluster_indices = np.where(clusters == happy_cluster)[0]\n",
    "\n",
    "# Use these indices to fetch the corresponding data points from the original data X\n",
    "happy_cluster_data_points = trace_representations[happy_cluster_indices, :]\n",
    "\n",
    "# Calculate the centroid as the mean of these data points\n",
    "happy_cluster_centroid = np.mean(happy_cluster_data_points, axis=0)\n",
    "\n",
    "print(\"Centroid of happy cluster:\", happy_cluster_centroid)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2eb704ff",
   "metadata": {},
   "source": [
    "# Distance Measurement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce6f9e52",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import euclidean\n",
    "\n",
    "# Calculate the Euclidean distance from each data point in X to the happy_cluster_centroid\n",
    "distances_to_centroid = [euclidean(trace_representations[i], happy_cluster_centroid) for i in range(len(trace_representations))]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5041b2f3",
   "metadata": {},
   "source": [
    "# Results overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6648d6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframe with necessary information for distance measurement\n",
    "\n",
    "grouped = dataframe.groupby('@@case_index')['concept:name'].apply(list).reset_index(name='trace')\n",
    "\n",
    "results = pd.DataFrame(grouped['trace'])\n",
    "\n",
    "results['cluster'] = clusters\n",
    "\n",
    "conformity_array = [int(trace['fitness']) for trace in alignments]\n",
    "results['conform'] = conformity_array\n",
    "\n",
    "results['distance'] = distances_to_centroid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f62e5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary = results.groupby('cluster').agg(\n",
    "    count=pd.NamedAgg(column='trace', aggfunc='size'),\n",
    "    conform_count=pd.NamedAgg(column='conform', aggfunc='sum')\n",
    ").reset_index()\n",
    "\n",
    "print(\"cluster\\tcount\\tconform_count\")\n",
    "for _, row in summary.iterrows():\n",
    "    print(f\"{row['cluster']}\\t{row['count']}\\t{row['conform_count']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3fba7067",
   "metadata": {},
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "364bd017",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Filter the DataFrame into conforming and non-conforming subsets\n",
    "conforming_distances = results[results['conform'] == 1]['distance']\n",
    "non_conforming_distances = results[results['conform'] == 0]['distance']\n",
    "\n",
    "# Determine common bin edges\n",
    "min_distance = min(results['distance'])\n",
    "max_distance = max(results['distance'])\n",
    "bin_edges = np.linspace(min_distance, max_distance, num=30)\n",
    "\n",
    "# Combine the data and reshape for k-means\n",
    "all_distances = results['distance']\n",
    "all_distances = np.array(all_distances)\n",
    "all_distances_reshaped = all_distances.reshape(-1, 1)\n",
    "\n",
    "# Apply k-means clustering\n",
    "kmeans = KMeans(n_clusters=2, random_state=0).fit(all_distances_reshaped)\n",
    "kmeans_labels = kmeans.labels_\n",
    "\n",
    "# Find the threshold as the average of the two cluster centers\n",
    "threshold_value = np.mean(kmeans.cluster_centers_)\n",
    "\n",
    "# Plot histograms and the threshold\n",
    "plt.hist(conforming_distances, bins=bin_edges, alpha=0.5, label='Conforming', color='green')\n",
    "plt.hist(non_conforming_distances, bins=bin_edges, alpha=0.5, label='Non-Conforming', color='red')\n",
    "plt.axvline(threshold_value, color='blue', linestyle='dashed', linewidth=1, label='Threshold')\n",
    "plt.xlabel('Distance')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend(loc='upper right')\n",
    "plt.title(f'Threshold at {threshold_value:.2f}')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fd070e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "true_positive = np.sum(results[results['conform'] == 1]['distance'] < threshold_value)\n",
    "true_negative = np.sum(results[results['conform'] == 0]['distance'] > threshold_value)\n",
    "false_positive = np.sum(results[results['conform'] == 0]['distance'] < threshold_value)\n",
    "false_negative = np.sum(results[results['conform'] == 1]['distance'] > threshold_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e04a00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate accuracy\n",
    "accuracy = (true_positive + true_negative) / (true_positive + true_negative + false_positive + false_negative)\n",
    "print(f\"Accuracy: {accuracy:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e40f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate precision\n",
    "precision = true_positive / (true_positive + false_positive)\n",
    "print(f\"Precision: {precision:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ecc678",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate recall\n",
    "recall = true_positive / (true_positive + false_negative)\n",
    "print(f\"Recall: {recall:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c99f41",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate f1\n",
    "f1 = 2 * ((precision * recall) / (precision + recall))\n",
    "print(f\"F1: {f1:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34bfa412",
   "metadata": {},
   "source": [
    "# Dev (Non Conform Traces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fac3418",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate precision for Dev\n",
    "precision = true_negative / (true_negative + false_negative)\n",
    "print(f\"Precision: {precision:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b4b08f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate recall for Dev\n",
    "recall = true_negative / (true_negative + false_positive)\n",
    "print(f\"Recall: {recall:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b4cc340",
   "metadata": {},
   "source": [
    "# No Dev (Conform Traces)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c84b511",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate precision for No Dev\n",
    "precision = true_positive / (true_positive + false_positive)\n",
    "print(f\"Precision: {precision:.3f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bcc6d9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate recall for No Dev\n",
    "recall = true_positive / (true_positive + false_negative)\n",
    "print(f\"Recall: {recall:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78e4769a",
   "metadata": {},
   "source": [
    "# AUC_ROC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933337f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UPDATED\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_curve, roc_auc_score\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Assuming 'results' is your DataFrame and 'distance' is the score to predict conformity\n",
    "\n",
    "# Inverting the 'distance' scores because higher scores indicate non-conformity\n",
    "# We invert the scores for ROC AUC calculation because roc_auc_score expects higher values\n",
    "# to indicate higher likelihood of the positive class\n",
    "inverted_scores = 1 - results['distance']\n",
    "\n",
    "# Calculate the ROC curve and AUC using inverted scores\n",
    "fpr, tpr, thresholds = roc_curve(results['conform'], inverted_scores, pos_label=1)\n",
    "roc_auc = roc_auc_score(results['conform'], inverted_scores)\n",
    "\n",
    "# Plot ROC curve\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr, color='orange', label=f'ROC curve (area = {roc_auc:0.2f})')\n",
    "plt.plot([0, 1], [0, 1], color='darkblue', linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()\n",
    "\n",
    "# Print the AUC\n",
    "print(f\"ROC AUC: {roc_auc:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
